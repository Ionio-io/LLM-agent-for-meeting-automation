{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains in Langchain\n",
    "\n",
    "In langchain, chain is a series or chain of different components which can connected with each other and can pass input and output to process data. These chains are created by one or more LLMs. For example, if you want to generate some data using LLM and then you want to use that output as an input for another LLM then you can create a chain for this purpose.\n",
    "\n",
    "We use `SimpleSequencialChain` when we have only one input and single output in a chain. For example, we have a cuisine and we want to generate restaurant name from given cuisine name and from that name we want to generate 10 dishes to add in menu.\n",
    "\n",
    "As we can see here one task is dependent on other and here is where we will create our first chain so letâ€™s code it.\n",
    "\n",
    "First install openai and langchain modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s first setup our LLM, we will use GPT-3.5 Turbo model for this tutorial. Get your api key from openai dashboard and add it as a environment variable in your code as itâ€™s recommended to keep it private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "OpenAI_LLM = OpenAI(temperature=0.6,api_key=os.environ[\"OPENAI_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here temperature shows the creativity of output, the more temperature is the more creative answer you will get and its not recommended for any calculation related output but its very useful for content writing.\n",
    "\n",
    "Now we have LLM setup so letâ€™s try it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = OpenAI_LLM(\"Say hello if you are working!\")\n",
    "print(bot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running it you will get an output from LLM saying hello and now our LLM is working perfectly!\n",
    "\n",
    "So letâ€™s create a chain, but first we will need to create prompt template for our LLM which we can create using PromptTemplate from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# Create first chain\n",
    "prompt_1 = PromptTemplate.from_template(\n",
    "    \"Give me a {cuisine} restaurant name. Only return name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here cuisine is an input from user and it will be automatically added in our prompt dynamically. so now we have our prompt and LLM ready so now we can create chain using LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "first_chain = LLMChain(llm=OpenAI_LLM,prompt=prompt_1)\n",
    "# To run this chain use below code\n",
    "# first_chain.run(\"Indian\") // Passing cuisine parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our first chain is ready which will give us restaurant name. Now create one more chain which will give us food items list for the given restaurant name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create second chain\n",
    "prompt_2 = PromptTemplate.from_template(\n",
    "    \"Give me 10 dish names for restaurant {restaurant}\"\n",
    ")\n",
    "second_chain = LLMChain(llm=OpenAI_LLM,prompt=prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now letâ€™s combine these 2 chains using SimpleSequencialChain . The order of chains matters in sequential chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these 2 chains\n",
    "final_chain = SimpleSequentialChain(chains=[first_chain,second_chain])\n",
    "response = final_chain.run(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we run this code, we will get name of 10 dishes based on given cuisine and restaurant name!\n",
    "\n",
    "### Creating Sequential chain\n",
    "But what if we want both restaurant name and dishes name in output? ðŸ¤”\n",
    "\n",
    "This is where `SequentialChain` comes into picture, it allows us to have multiple inputs and outputs unlike SimpleSequentialChain . so letâ€™s try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first chain\n",
    "prompt_1 = PromptTemplate.from_template(\n",
    "    \"Give me a {cuisine} restaurant name. Only return name\"\n",
    ")\n",
    "# here we will specify output_key which will be used in next chain as an input\n",
    "first_chain = LLMChain(llm=OpenAI_LLM,prompt=prompt_1,output_key=\"restaurant_name\")\n",
    "# Create second chain\n",
    "prompt_2 = PromptTemplate.from_template(\n",
    "    \"Give me 10 dish names for restaurant {restaurant}\"\n",
    ")\n",
    "second_chain = LLMChain(llm=OpenAI_LLM,prompt=prompt_2,output_key=\"dishes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now letâ€™s combine both chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "# Combining both chains into sequential chain\n",
    "final_sequencial_chain = SequentialChain(\n",
    "    input_variables=[\"cuisine\"],\n",
    "    # we want c and result both in output \n",
    "    output_variables=[\"restaurant_name\",\"dishes\"],\n",
    "    chains=[first_chain,second_chain]\n",
    ")\n",
    "# In sequencial chain, we can have multiple inputs so use tuple here for parameters.\n",
    "final_sequencial_chain({\"cuisine\":\"Mexican\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code, we will get both restaurant name and dishes list and this is how you can create chains using langchain according to your usecases."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
