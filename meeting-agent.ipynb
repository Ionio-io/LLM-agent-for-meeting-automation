{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meeting Automation LLM agent\n",
    "We will create an agent which will do following tasks:\n",
    "\n",
    "- Get information about a prospect & their idea from internet when a call is booked\n",
    "- Find possible solution about idea from internet\n",
    "- Create professional project proposal from given idea,client information and solution with other information like tech stack, timeline etc\n",
    "- Save the project proposal as notion document or word document\n",
    "\n",
    "First of all, let’s setup our LLM. we will use gpt-4 model for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants # create your own constants.py file to store api keys\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY') or 'OPENAI_API_KEY'\n",
    "OPENAI_API_KEY = constants.OPENAI_API_KEY\n",
    "\n",
    "# initialize LLM (we use ChatOpenAI because we'll later define a `chat` agent)\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    temperature=0.6,\n",
    "    model_name='gpt-4'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4 is a conversational model, so it will store all previous conversations in a local memory to get the context for current message so it takes the previous messages and sends the full conversation as a context in prompt so that model can understand the context for current message but suppose if there are more than 100 messages then the context will become so much longer and it won’t fit in context window of model. That’s why we will only send last k number of conversations in context and to do that we can use ConversationBufferWindowMemory method with k parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "# initialize conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create our first tool which is platform info extractor. To create any custom tool in langchain, you will have to create a class with following properties:\n",
    "\n",
    "- **name**: name of the tool\n",
    "- **description**: description about the tool so that agent will know when to use this tool\n",
    "- **_run()**: this method will be triggered when agent uses the tool so add your business logic in this method\n",
    "- **_arun()**: this method will be triggered when someone calls agent asynchronously.\n",
    "We will have to inherit properties of BaseTool class which comes from langchain.tools\n",
    "\n",
    "We will use perplexity api to get the information from internet and for that we will use their online model `pplx-70b-online`. You can get your own api key from perplexity dashboard.\n",
    "\n",
    "here is the code for platform info extractor tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity setup\n",
    "from langchain.tools import BaseTool\n",
    "# Creating tool to get information about given website or platform\n",
    "import requests\n",
    "import json\n",
    "class GetClientDetails(BaseTool):\n",
    "    name = \"Client details extractor\"\n",
    "    description = \"use this tool when you have given a platform name, idea or platform link and you want to find more information about CEO of platform and proposed idea\"\n",
    "    def _run(self, website):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"pplx-70b-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are artificial intelligence agent which extracts an information by searching about it online\"\n",
    "                        \"and returns information in this format if it exists\"\n",
    "                        \"Title of website or platform: \"\n",
    "                        \"Proposed idea:\"\n",
    "                        \"CEO Information:\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"I am giving you platform name,idea or platform link and you have to find latest information about\" \n",
    "                        \"the platform by going to given link and return atleast 200 words description about idea and\"\n",
    "                        \"atleast 150 words description about CEO, their goal and achievements\"\n",
    "                        \"Please try to make it as detailed as you can and always refer to online information\"\n",
    "                        \"here is the platform link or name \"\n",
    "                        f\"{str(website)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create our second tool which is client details extractor tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI as OpenAI_Agent\n",
    "class GetPlatformInfo(BaseTool):\n",
    "    name = \"Platform info extractor\"\n",
    "    description = \"use this tool when you have given a description about meeting and you have to find the proposed idea, client name or platform link from given description\"\n",
    "\n",
    "    def _run(self, description):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"pplx-70b-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have given a description of meeting and you will have to find out proposed idea, client name and website link mentioned in the given description.\"\n",
    "                        \"Use client info extractor tool to get more information.\"\n",
    "                        \"Return it in this format\"\n",
    "                        \"Idea: <idea>\"\n",
    "                        \"Client Info: <client_info>\"\n",
    "                        \"Platform Link: <platform_link>\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"if anything is not provided in description then use internet and google search to find out the actual information\"\n",
    "                        \"Here is the meeting description \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create our last tool called solution extractor which will take the idea and give us possible solution for the given idea or problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GetIdeaSolution(BaseTool):\n",
    "    name = \"Solution extractor\"\n",
    "    description = \"use this tool when you have given an idea description and information about client and you have to find solution on how we can achieve the given idea\"\n",
    "\n",
    "    def _run(self, description):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"pplx-70b-online\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have given an idea description and you have to find around 3-4 solutions to achieve the given idea using AI-ML\"\n",
    "                        \"or webdev technologies. Search online about tech stack, resources, timeline of project and youtube videos and send it with proper formatting and line breaks in this format\"\n",
    "                        \"Solution: <solution>\"\n",
    "                        \"Tech stack: <tech_stack>\"\n",
    "                        \"Timeline: <timeline>\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Here is the idea description \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s initialize our agent and add all the tools in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Agent\n",
    "from langchain.agents import initialize_agent\n",
    "tools = [GetClientDetails(),GetPlatformInfo(),GetIdeaSolution()]\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it’s time to test our agent 👀 !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = agent(\n",
    "      \"First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words\"\n",
    "      \"fetch realtime data from internet everytime\"\n",
    "      \"This information is going to be added in project proposal so please write in detail and sections like CEO_Info,idea and solution must be explained in 600 words each.\"\n",
    "      \"Return your response in python dict format like below and please use proper line breaks: \"\n",
    "      \"\"\"\n",
    "      \"platform_name\": platform_name\n",
    "      \"CEO_Name\": ceo_name\n",
    "      \"idea\": idea\n",
    "      \"solution\": solution\n",
    "      \"tech_stack\": tech stack\n",
    "      \"timeline\": timeline\n",
    "      \"Platform_link\": platform_link\n",
    "      \"\"\"\n",
    "      \"Here is the description:\"\n",
    "      \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\n",
    "      )\n",
    "output = json.loads(para[\"output\"])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use gpt-4 to format this details so that it can be added in notion as a project proposal (This step is optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=constants.OPENAI_API_KEY)\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                I am giving you some data in python dict format and you will have to add more information by searching about it online in given data so that it can be added in project proposal but don't add any fake information. Once you got the information then return the data in the same format.\n",
    "                Try to add more information by yourself too to make it more detailed and make it around 1000 words. Don't return anything except this dictionary and also please use proper line breaks in every paragraph of each section of dict.\n",
    "                Here is the information about fields in the given dict: \n",
    "                platform_name: Name of platform\n",
    "                CEO_Info: Background about CEO and information about CEO\n",
    "                CEO_Name: Name of CEO\n",
    "                idea: project idea\n",
    "                solution: solution on how we can solve the given problem statement and how to achieve the given idea\n",
    "                tech_stack: tech stack used to build the solution\n",
    "                timeline: timeline for the project\n",
    "                Platform_link: link to the platform\n",
    "                Here is the data: \n",
    "                {para[\"output\"]}\n",
    "            \"\"\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")\n",
    "output = chat_completion.choices[0].message.content\n",
    "output = json.loads(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding data to notion\n",
    "Now we have all the information about client, their idea and organization, so let’s format it to make it as a project proposal and add it in notion as a notion document. we will use `notion_client` module from notion.\n",
    "\n",
    "Start by installing the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install notion_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding data into notion\n",
    "from notion_client import Client\n",
    "\n",
    "notion = Client(auth=constants.NOTION_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s write code to add all our data into notion document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "parent = {\"type\": \"page_id\",\"page_id\": \"14ffc7f5-774f-46d6-8653-e6f24dfae758\"}\n",
    "properties = {\n",
    "    \"title\": {\n",
    "        \"type\": \"title\",\n",
    "        \"title\": [{ \"type\": \"text\", \"text\": { \"content\": f\"Meeting with {output['CEO_Name']} about {output['platform_name']}\" } }]\n",
    "    },\n",
    "}\n",
    "children = [\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_2\",\n",
    "        \"heading_2\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"🚀 Platform Name\" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['platform_name'] } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_2\",\n",
    "        \"heading_2\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"📝 Idea Description\" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['idea'] } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_2\",\n",
    "        \"heading_2\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"💡 How we can help?\" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['solution'] } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_3\",\n",
    "        \"heading_3\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"⚒️ What tech stack we can use?\" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['tech_stack'] } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_3\",\n",
    "        \"heading_3\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"⌛ What is timeline of project? \" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['timeline'] } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_3\",\n",
    "        \"heading_3\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"🤔 Info about CEO\" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['CEO_Info'] } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"heading_2\",\n",
    "        \"heading_2\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"🔗 Platform Link \" } }]\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"object\": \"block\",\n",
    "        \"type\": \"paragraph\",\n",
    "        \"paragraph\": {\n",
    "          \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": output['Platform_link'] } }]\n",
    "        }\n",
    "      },\n",
    "    ]\n",
    "create_page_response = notion.pages.create(\n",
    "    parent=parent,properties=properties,children=children\n",
    ")\n",
    "pprint(create_page_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating proposal as a word document\n",
    "The main problem with notion formatting is that everything needs to be converted into notion object which you already saw above in code and you can’t write an object for every single paragraph, list or heading to make your document good so instead of using notion we will try to get an output in markdown from our agent and then convert that text into an actual word document.\n",
    "\n",
    "Let’s change the part where we made our last openai call for formatting. Instead of getting python dictionary response, we will tell model to give response in markdown\n",
    "\n",
    "Make these changes in your previous code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for creating a markdown for our proposal\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=constants.OPENAI_API_KEY)\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                I am giving you some data in python dict format and you will have to add more information in it and convert it in markdown file with below format\n",
    "                Don't use anything except headings and paragraphs in markdown\n",
    "                # Project name\n",
    "                project name\n",
    "                # Who is the client?\n",
    "                information about client\n",
    "                # What is the idea?\n",
    "                information about idea\n",
    "                # How can we help?\n",
    "                detailed information about solution\n",
    "                # Tech stack\n",
    "                information about tech stack\n",
    "                # Timeline\n",
    "                information about timeline\n",
    "                Try to add more information by yourself too to make it more detailed and make it around 800 words. Don't return anything except markdown and use proper line breaks.\n",
    "                Here is the information about fields in the given dict: \n",
    "                platform_name: Name of platform\n",
    "                CEO_Info: Background about CEO and information about CEO\n",
    "                CEO_Name: Name of CEO\n",
    "                idea: project idea\n",
    "                solution: solution on how we can solve the given problem statement and how to achieve the given idea\n",
    "                tech_stack: tech stack used to build the solution\n",
    "                timeline: timeline for the project\n",
    "                Platform_link: link to the platform\n",
    "                Here is the data: \n",
    "                {para[\"output\"]}\n",
    "            \"\"\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.7\n",
    ")\n",
    "output = chat_completion.choices[0].message.content\n",
    "print(output)\n",
    "# output = json.loads(output)\n",
    "# print(json_output[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have our project proposal as a markdown text so now its time to convert it into word document and we can easily do that with pypandoc which is a python wrapper for pandoc.\n",
    "\n",
    "Let’s install it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypandoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to provide our markdown text and it will convert it into word document. So let’s try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "output = pypandoc.convert_text(output, 'docx', format='md', outputfile=\"output.docx\")\n",
    "# output = json.loads(output.output)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
